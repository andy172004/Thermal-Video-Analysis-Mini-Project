{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Project "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "General Steps I followed for execution of my task.\n",
    "\n",
    "Track Connected Components Over Time: For each connected component detected in the first frame, you'll need to track its intensity or frequency changes across subsequent frames (2nd to 516th). Here's a general approach:\n",
    "\n",
    "a. Initialize Data Structures: Create data structures to store information about each connected component detected in the first frame. This could include the component's ID, position, intensity or frequency, and any other relevant attributes.\n",
    "\n",
    "b. Iterate Through Frames: Starting from the 2nd frame up to the 516th frame, apply the same connected component detection technique to each frame.\n",
    "\n",
    "c. Match Connected Components: For each frame, match the detected connected components with the ones detected in the first frame. You can use techniques like centroid matching or intersection over union (IoU) to match components between frames.\n",
    "\n",
    "d. Calculate Intensity Change or Frequency: Once components are matched between frames, calculate the intensity change or frequency of each connected component over time. Intensity change can be calculated by measuring the change in pixel intensity within the component's region of interest. Frequency change can be calculated based on how often the component appears in consecutive frames.\n",
    "\n",
    "e. Store Data: Store the calculated intensity change or frequency for each connected component over time.\n",
    "\n",
    "Filter Components by Frequency: After processing frames 1 to 516, filter out the connected components whose frequency falls between 0 and 1 Hz.\n",
    "\n",
    "Repeat Process for Subsequent Frames: Repeat the above steps for the 517th to 1032nd frames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from scipy.spatial import distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Detection of components , calculating centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_components(frame):\n",
    "    img_grey=cv2.cvtColor( frame,cv2.COLOR_BGR2GRAY)\n",
    "    _, binary_image = cv2.threshold(img_grey, 50, 255, cv2.THRESH_BINARY)# random threshold\n",
    "    num_labels, labels = cv2.connectedComponents(binary_image, connectivity=8)\n",
    "    \n",
    "    components_image = np.zeros_like(frame, dtype=np.uint8)\n",
    "    centroids = []\n",
    "    for label in range(1, num_labels):  # Skip background label 0\n",
    "        # Extract the connected component by filtering based on the label\n",
    "        component = np.where(labels == label, 255, 0).astype(np.uint8)\n",
    "\n",
    "        # Calculate the moments of the connected component\n",
    "        moments = cv2.moments(component)\n",
    "\n",
    "        # Calculate centroid coordinates\n",
    "        if moments[\"m00\"] != 0:\n",
    "            centroid_x = int(moments[\"m10\"] / moments[\"m00\"])\n",
    "            centroid_y = int(moments[\"m01\"] / moments[\"m00\"])\n",
    "            centroids.append((centroid_x, centroid_y))\n",
    "    \n",
    "        # Calculate intensity of the connected component\n",
    "        # intensity = np.sum(frame[labels == label]) / np.sum(labels == label)\n",
    "    \n",
    "        # Convert the component to a 3-channel image\n",
    "        component = cv2.cvtColor(component, cv2.COLOR_GRAY2BGR)\n",
    "    \n",
    "        # Draw the connected component on the blank image\n",
    "        components_image += component\n",
    "\n",
    "        # Print intensity of the connected component\n",
    "        #print(f\"Intensity of component {label}: {intensity}\")\n",
    "        # intensity_components.append(intensity)\n",
    "    return components_image,num_labels,centroids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matching Components "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def centroid_matching(centroids_frame1, centroids_frame2, threshold):\n",
    "    matched_component = []\n",
    "    for idx1, centroid1 in enumerate(centroids_frame1):\n",
    "        min_dist = float('inf')\n",
    "        for idx2, centroid2 in enumerate(centroids_frame2):\n",
    "            dist = distance.euclidean(centroid1, centroid2)\n",
    "            if dist < min_dist:\n",
    "                min_dist = dist\n",
    "        if min_dist < threshold:\n",
    "            matched_component.append(idx1)\n",
    "    return matched_component"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating the frame rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame rate: 25.0\n"
     ]
    }
   ],
   "source": [
    "video_reader = cv2.VideoCapture('C:/Users/muska/Downloads/1705951007967.mp4')\n",
    "# Check if the video opened successfully\n",
    "if not video_reader.isOpened():\n",
    "    print(\"Error: Could not open video.\")\n",
    "    exit()\n",
    "\n",
    "# Get the frame rate of the video\n",
    "frame_rate =video_reader.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "print(\"Frame rate:\", frame_rate)\n",
    "\n",
    "video_reader.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_reader = cv2.VideoCapture('C:/Users/muska/Downloads/1705951007967.mp4')\n",
    "number_of_frames = 516\n",
    "while (True):\n",
    " ret, frame=video_reader.read()\n",
    " colored_labels_1 , Number_of_comp1 , centroid_1 = detect_components(frame)\n",
    " component_counter =[0] * Number_of_comp1\n",
    " #iterate\n",
    " i=2\n",
    " while(i<=number_of_frames):\n",
    "  i=i+1\n",
    "  ret, frame=video_reader.read()\n",
    "  colored_labels , Number_of_comp , centroid = detect_components(frame)\n",
    "  matched_components = centroid_matching(centroid_1, centroid,0.01)# random threshold\n",
    "  for index, component in enumerate(matched_components):\n",
    "    component_counter[component] = 1 + component_counter[component]\n",
    "\n",
    " frequency = []\n",
    " for i in range (0, len(component_counter)):\n",
    "    frequency.append(component_counter[i] / (number_of_frames / frame_rate))\n",
    "\n",
    " img_grey=cv2.cvtColor( frame,cv2.COLOR_BGR2GRAY)\n",
    " _, binary_image = cv2.threshold(img_grey, 50, 255, cv2.THRESH_BINARY)# random threshold\n",
    " num_labels, labels = cv2.connectedComponents(binary_image, connectivity=8)\n",
    " components_image = np.zeros_like(frame, dtype=np.uint8)\n",
    " for f in range (1, len(frequency)):\n",
    "    if (frequency[f]<=1):\n",
    "        component = np.where(labels == f, 255, 0).astype(np.uint8)\n",
    "         # Convert the component to a 3-channel image\n",
    "        component = cv2.cvtColor(component, cv2.COLOR_GRAY2BGR)\n",
    "    \n",
    "        # Draw the connected component on the blank image\n",
    "        components_image += component\n",
    " cv2.imshow('Video',frame)\n",
    " cv2.imshow('Video2',components_image)\n",
    " if (cv2.waitKey(1) & 0xFF == ord('q')):\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
